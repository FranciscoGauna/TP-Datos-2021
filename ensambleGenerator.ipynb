{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "import pandas as pd\r\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "df_train_labels_original = pd.read_csv('train_labels.csv',low_memory=False,index_col='building_id')\r\n",
    "df_train_values_original = pd.read_csv('train_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})\r\n",
    "df_test_values_original = pd.read_csv('test_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "train_values_subset = pd.get_dummies(df_train_values_original)\r\n",
    "train_labels_subset = df_train_labels_original['damage_grade']\r\n",
    "\r\n",
    "validation_size = df_train_values_original.index.size - df_test_values_original.index.size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "train_values, validation_values = (train_values_subset.iloc[0:173733], train_values_subset.iloc[173733:-1])\r\n",
    "train_labels, validation_labels = (train_labels_subset.iloc[0:173733], train_labels_subset.iloc[173733:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "redNeuronalPredictionsTrain = pd.read_csv('ensamble_train_feda.csv', index_col=0)\r\n",
    "redNeuronalPredictionsTrain = df_train_labels_original.merge(redNeuronalPredictionsTrain, how='left', on=\"building_id\").iloc[173733:-1].reset_index()\r\n",
    "redNeuronalPredictionsTest = pd.read_csv('ensamble_test_feda.csv', index_col=0).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "xgBoostPredictionsTest = pd.read_csv('xgBoostPredictionProba.csv', index_col=0)\r\n",
    "xgBoostPredictionsTrain = pd.read_csv('xgBoostPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "lightGBMPredictionsTest = pd.read_csv('lightGBMPredictionProba.csv', index_col=0)\r\n",
    "lightGBMPredictionsTrain = pd.read_csv('lightGBMPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "rndForestPredictionsTest = pd.read_csv('randomForestPredictionProba', index_col=0)\r\n",
    "rndForestPredictionsTrain = pd.read_csv('randomForestPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "logRegPredictionsTest = pd.read_csv('LogisticRegresionProbaTest.csv', index_col=0)\r\n",
    "logRegPredictionsTrain = pd.read_csv('LogisticRegresionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "trainData = pd.concat([rndForestPredictionsTrain, xgBoostPredictionsTrain, redNeuronalPredictionsTrain, lightGBMPredictionsTrain, logRegPredictionsTrain], axis=1 ).drop(columns=[\"building_id\", \"damage_grade\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "testData = pd.concat([rndForestPredictionsTest, xgBoostPredictionsTest, redNeuronalPredictionsTest, lightGBMPredictionsTest, logRegPredictionsTest], axis=1 ).drop(columns=[\"building_id\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "# esta a fuerza bruta, pero lleva poco tiempo en definitiva\r\n",
    "scores = []\r\n",
    "for a in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]:\r\n",
    "    for b in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]:\r\n",
    "        for c in [0.61, 0.62, 0.63, 0.64, 0.65, 0.56, 0.57, 0.58, 0.59]:\r\n",
    "            for d in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]:\r\n",
    "                for e in [0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2]:\r\n",
    "                    if (a+b+c+d+e != 1): continue\r\n",
    "                    else:\r\n",
    "                        trainData2 = trainData\r\n",
    "                        trainData2 = trainData2.assign(dg1 = lambda x: (x.rndf1 * a) + (x.neural1 * b) + (x.xgb1 * c) + (x.logReg1 * d) + (x.gbm1 * e))\r\n",
    "                        trainData2 = trainData2.assign(dg2 = lambda x: (x.rndf2 * a) + (x.neural2 * b) + (x.xgb2 * c) + (x.logReg2 * d) + (x.gbm2 * e))\r\n",
    "                        trainData2 = trainData2.assign(dg3 = lambda x: (x.rndf3 * a) + (x.neural3 * b) + (x.xgb3 * c) + (x.logReg3 * d) + (x.gbm3 * e))\r\n",
    "                        trainData2 = trainData2[['dg1', 'dg2', 'dg3']]\r\n",
    "                        dgTest = []\r\n",
    "                        for x in range(0, 86867):\r\n",
    "                            dgTest.append(1 if ((trainData2.dg1[x] > trainData2.dg2[x]) and (trainData2.dg1[x] > trainData2.dg3[x])) else 2 if ((trainData2.dg2[x] > trainData2.dg3[x]) and (trainData2.dg2[x] > trainData2.dg1[x])) else 3)\r\n",
    "                        score = f1_score(validation_labels, dgTest, average='micro')\r\n",
    "                        scores.append([score, a, b, c, d, e])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "max(scores, key= lambda x: x[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.7459219266234588, 0.1, 0.05, 0.65, 0.1, 0.1]"
      ]
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "# esta a fuerza bruta, pero lleva poco tiempo en definitiva\r\n",
    "scores = []\r\n",
    "for a in [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]:\r\n",
    "    for b in [0.05, 0.11, 0.12, 0.13, 0.14, 0.15, 0.06, 0.07, 0.08, 0.09]:\r\n",
    "        for c in [0.9, 0.92, 0.93, 0.94, 0.85, 0.86, 0.87, 0.88, 0.89, 0.91]:\r\n",
    "            if (a+b+c != 1): continue\r\n",
    "            else:\r\n",
    "                trainData2 = trainData\r\n",
    "                trainData2 = trainData2.assign(dg1 = lambda x: (x.gbm1 * a) + (x.neural1 * b) + (x.xgb1 * c))\r\n",
    "                trainData2 = trainData2.assign(dg2 = lambda x: (x.gbm2 * a) + (x.neural2 * b) + (x.xgb2 * c))\r\n",
    "                trainData2 = trainData2.assign(dg3 = lambda x: (x.gbm3 * a) + (x.neural3 * b) + (x.xgb3 * c))\r\n",
    "                trainData2 = trainData2[['dg1', 'dg2', 'dg3']]\r\n",
    "                dgTest = []\r\n",
    "                for x in range(0, 86867):\r\n",
    "                    dgTest.append(1 if ((trainData2.dg1[x] > trainData2.dg2[x]) and (trainData2.dg1[x] > trainData2.dg3[x])) else 2 if ((trainData2.dg2[x] > trainData2.dg3[x]) and (trainData2.dg2[x] > trainData2.dg1[x])) else 3)\r\n",
    "                score = f1_score(validation_labels, dgTest, average='micro')\r\n",
    "                scores.append([score, a, b, c])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "max(scores, key= lambda x: x[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.7464284480873059, 0.01, 0.08, 0.91]"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[0.7488574487434814, 0.1, 0.3, 0.5, 0.1]\r\n",
    "[0.7505151553524353, 0.07, 0.33, 0.53, 0.07]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "testData = testData.assign(dg1 = lambda x: (x.gbm1 * 0.01) + (x.neural1 * 0.08) + (x.xgb1 * 0.91))\r\n",
    "testData = testData.assign(dg2 = lambda x: (x.gbm2 * 0.01) + (x.neural2 * 0.08) + (x.xgb2 * 0.91))\r\n",
    "testData = testData.assign(dg3 = lambda x: (x.gbm3 * 0.01) + (x.neural3 * 0.08) + (x.xgb3 * 0.91))\r\n",
    "testData = testData[['dg1', 'dg2', 'dg3']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "dgFinal = []\r\n",
    "for x in range(0, 86868):\r\n",
    "    dgFinal.append(1 if ((testData.dg1[x] > testData.dg2[x]) and (testData.dg1[x] > testData.dg3[x])) else 2 if ((testData.dg2[x] > testData.dg3[x]) and (testData.dg2[x] > testData.dg1[x])) else 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\r\n",
    "my_submission = pd.DataFrame(data=dgFinal,\r\n",
    "                             columns=submission_format.columns,\r\n",
    "                             index=submission_format.index)\r\n",
    "my_submission.to_csv('submissionEnsamble.csv')\r\n",
    "my_submission"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             damage_grade\n",
       "building_id              \n",
       "300051                  3\n",
       "99355                   2\n",
       "890251                  2\n",
       "745817                  1\n",
       "421793                  3\n",
       "...                   ...\n",
       "310028                  2\n",
       "663567                  2\n",
       "1049160                 2\n",
       "442785                  2\n",
       "501372                  2\n",
       "\n",
       "[86868 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300051</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99355</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890251</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421793</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310028</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663567</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049160</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442785</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501372</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86868 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.74561110663428 primer intento ensamble con solver = 'lbfgs'"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "88ce181b8cd0eb812200b9b411a136cd9c7c972aa91497a27a228178326dd49d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}