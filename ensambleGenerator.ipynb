{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_train_labels_original = pd.read_csv('train_labels.csv',low_memory=False,index_col='building_id')\r\n",
    "df_train_values_original = pd.read_csv('train_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})\r\n",
    "df_test_values_original = pd.read_csv('test_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_values_subset = pd.get_dummies(df_train_values_original)\r\n",
    "train_labels_subset = df_train_labels_original['damage_grade']\r\n",
    "\r\n",
    "validation_size = df_train_values_original.index.size - df_test_values_original.index.size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_values, validation_values = (train_values_subset.iloc[0:173733], train_values_subset.iloc[173733:-1])\r\n",
    "train_labels, validation_labels = (train_labels_subset.iloc[0:173733], train_labels_subset.iloc[173733:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "redNeuronalPredictionsTrain = pd.read_csv('ensamble_train_feda.csv', index_col=0)\r\n",
    "redNeuronalPredictionsTrain = df_train_labels_original.merge(redNeuronalPredictionsTrain, how='left', on=\"building_id\").iloc[173733:-1].reset_index()\r\n",
    "redNeuronalPredictionsTest = pd.read_csv('ensamble_test_feda.csv', index_col=0).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "xgBoostPredictionsTest = pd.read_csv('xgBoostPredictionProba.csv', index_col=0)\r\n",
    "xgBoostPredictionsTrain = pd.read_csv('xgBoostPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "lightGBMPredictionsTest = pd.read_csv('lightGBMPredictionProba.csv', index_col=0)\r\n",
    "lightGBMPredictionsTrain = pd.read_csv('lightGBMPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "rndForestPredictionsTest = pd.read_csv('randomForestPredictionProba.csv', index_col=0)\r\n",
    "rndForestPredictionsTrain = pd.read_csv('randomForestPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "logRegPredictionsTest = pd.read_csv('LogisticRegresionProbaTest.csv', index_col=0)\r\n",
    "logRegPredictionsTrain = pd.read_csv('LogisticRegresionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "trainData = pd.concat([rndForestPredictionsTrain, xgBoostPredictionsTrain, redNeuronalPredictionsTrain, lightGBMPredictionsTrain, logRegPredictionsTrain], axis=1 ).drop(columns=[\"building_id\", \"damage_grade\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "testData = pd.concat([rndForestPredictionsTest, xgBoostPredictionsTest, redNeuronalPredictionsTest, lightGBMPredictionsTest, logRegPredictionsTest], axis=1 ).drop(columns=[\"building_id\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# esta a fuerza bruta, pero lleva poco tiempo en definitiva\r\n",
    "scores = []\r\n",
    "for a in [0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2]:\r\n",
    "    for b in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]:\r\n",
    "        for c in [0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69]:\r\n",
    "            for d in [0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2]:\r\n",
    "                for e in [0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.]:\r\n",
    "                    if (a+b+c+d+e != 1): continue\r\n",
    "                    else:\r\n",
    "                        trainData2 = trainData\r\n",
    "                        trainData2 = trainData2.assign(dg1 = lambda x: (x.rndf1 * a) + (x.neural1 * b) + (x.xgb1 * c) + (x.logReg1 * d) + (x.gbm1 * e))\r\n",
    "                        trainData2 = trainData2.assign(dg2 = lambda x: (x.rndf2 * a) + (x.neural2 * b) + (x.xgb2 * c) + (x.logReg2 * d) + (x.gbm2 * e))\r\n",
    "                        trainData2 = trainData2.assign(dg3 = lambda x: (x.rndf3 * a) + (x.neural3 * b) + (x.xgb3 * c) + (x.logReg3 * d) + (x.gbm3 * e))\r\n",
    "                        trainData2 = trainData2[['dg1', 'dg2', 'dg3']]\r\n",
    "                        dgTest = []\r\n",
    "                        for x in range(0, 86867):\r\n",
    "                            dgTest.append(1 if ((trainData2.dg1[x] > trainData2.dg2[x]) and (trainData2.dg1[x] > trainData2.dg3[x])) else 2 if ((trainData2.dg2[x] > trainData2.dg3[x]) and (trainData2.dg2[x] > trainData2.dg1[x])) else 3)\r\n",
    "                        score = f1_score(validation_labels, dgTest, average='micro')\r\n",
    "                        scores.append([score, a, b, c, d, e])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "max(scores, key= lambda x: x[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.7458643673662034, 0.13, 0.09, 0.67, 0.11, 0.0]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "testData = testData.assign(dg1 = lambda x: (x.gbm1 * 0.01) + (x.neural1 * 0.08) + (x.xgb1 * 0.91))\r\n",
    "testData = testData.assign(dg2 = lambda x: (x.gbm2 * 0.01) + (x.neural2 * 0.08) + (x.xgb2 * 0.91))\r\n",
    "testData = testData.assign(dg3 = lambda x: (x.gbm3 * 0.01) + (x.neural3 * 0.08) + (x.xgb3 * 0.91))\r\n",
    "testData = testData[['dg1', 'dg2', 'dg3']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "dgFinal = []\r\n",
    "for x in range(0, 86868):\r\n",
    "    dgFinal.append(1 if ((testData.dg1[x] > testData.dg2[x]) and (testData.dg1[x] > testData.dg3[x])) else 2 if ((testData.dg2[x] > testData.dg3[x]) and (testData.dg2[x] > testData.dg1[x])) else 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\r\n",
    "my_submission = pd.DataFrame(data=dgFinal,\r\n",
    "                             columns=submission_format.columns,\r\n",
    "                             index=submission_format.index)\r\n",
    "my_submission.to_csv('submissionEnsamble.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.74561110663428 primer intento ensamble con solver = 'lbfgs'"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "88ce181b8cd0eb812200b9b411a136cd9c7c972aa91497a27a228178326dd49d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}