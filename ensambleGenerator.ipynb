{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import pandas as pd\r\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df_train_labels_original = pd.read_csv('train_labels.csv',low_memory=False,index_col='building_id')\r\n",
    "df_train_values_original = pd.read_csv('train_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})\r\n",
    "df_test_values_original = pd.read_csv('test_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_values_subset = pd.get_dummies(df_train_values_original)\r\n",
    "train_labels_subset = df_train_labels_original['damage_grade']\r\n",
    "\r\n",
    "validation_size = df_train_values_original.index.size - df_test_values_original.index.size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "train_values, validation_values = (train_values_subset.iloc[0:173733], train_values_subset.iloc[173733:-1])\r\n",
    "train_labels, validation_labels = (train_labels_subset.iloc[0:173733], train_labels_subset.iloc[173733:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "redNeuronalPredictionsTrain = pd.read_csv('ensamble_predictions_feda.csv', index_col=0)\r\n",
    "redNeuronalPredictionsTest = pd.read_csv('ensamble_submition_feda.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "xgBoostPredictionsTest = pd.read_csv('xgBoostPredictionProba.csv', index_col=0)\r\n",
    "xgBoostPredictionsTrain = pd.read_csv('xgBoostPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "rndForestPredictionsTest = pd.read_csv('randomForestPredictionProba', index_col=0)\r\n",
    "rndForestPredictionsTrain = pd.read_csv('randomForestPredictionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "logRegPredictionsTest = pd.read_csv('LogisticRegresionProbaTest.csv', index_col=0)\r\n",
    "logRegPredictionsTrain = pd.read_csv('LogisticRegresionProbaTrain.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "trainData = pd.concat([rndForestPredictionsTrain , xgBoostPredictionsTrain, redNeuronalPredictionsTrain, logRegPredictionsTrain], axis=1 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "testData = pd.concat([rndForestPredictionsTest , xgBoostPredictionsTest, redNeuronalPredictionsTest, logRegPredictionsTest], axis=1 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# esta a fuerza bruta, pero lleva poco tiempo en definitiva\r\n",
    "scores = []\r\n",
    "for a in [0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13]:\r\n",
    "    for b in [0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33]:\r\n",
    "        for c in [0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53]:\r\n",
    "            for d in [0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13]:\r\n",
    "                if (a+b+c+d != 1): continue\r\n",
    "                else:\r\n",
    "                    trainData = pd.concat([rndForestPredictionsTrain , xgBoostPredictionsTrain, redNeuronalPredictionsTrain, logRegPredictionsTrain], axis=1 )\r\n",
    "                    trainData = trainData.assign(dg1 = lambda x: (x.rndf1 * a) + (x.neural1 * b) + (x.xgb1 * c) + (x.logReg1 * d))\r\n",
    "                    trainData = trainData.assign(dg2 = lambda x: (x.rndf2 * a) + (x.neural2 * b) + (x.xgb2 * c) + (x.logReg2 * d))\r\n",
    "                    trainData = trainData.assign(dg3 = lambda x: (x.rndf3 * a) + (x.neural3 * b) + (x.xgb3 * c) + (x.logReg3 * d))\r\n",
    "                    trainData = trainData[['dg1', 'dg2', 'dg3']]\r\n",
    "                    dgTest = []\r\n",
    "                    for x in range(0, 86867):\r\n",
    "                        dgTest.append(1 if ((trainData.dg1[x] > trainData.dg2[x]) and (trainData.dg1[x] > trainData.dg2[x])) else 2 if ((trainData.dg2[x] > trainData.dg3[x]) and (trainData.dg2[x] > trainData.dg1[x])) else 3)\r\n",
    "                    score = f1_score(validation_labels, dgTest, average='micro')\r\n",
    "                    scores.append([score, a, b, c, d])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "max(scores, key= lambda x: x[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.7505151553524353, 0.07, 0.33, 0.53, 0.07]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[0.7488574487434814, 0.1, 0.3, 0.5, 0.1]\r\n",
    "[0.7505151553524353, 0.07, 0.33, 0.53, 0.07]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "testData = testData.assign(dg1 = lambda x: (x.rndf1 * 0.25) + (x.neural1 * 0.25) + (x.xgb1 * 0.4) + (x.logReg1 * 0.1))\r\n",
    "testData = testData.assign(dg2 = lambda x: (x.rndf2 * 0.25) + (x.neural2 * 0.25) + (x.xgb2 * 0.4) + (x.logReg2 * 0.1))\r\n",
    "testData = testData.assign(dg3 = lambda x: (x.rndf3 * 0.25) + (x.neural3 * 0.25) + (x.xgb3 * 0.4) + (x.logReg3 * 0.1))\r\n",
    "testData = testData[['dg1', 'dg2', 'dg3']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "trainData = trainData.assign(dg1 = lambda x: (x.rndf1 * 0.07) + (x.neural1 * 0.33) + (x.xgb1 * 0.53) + (x.logReg1 * 0.07))\r\n",
    "trainData = trainData.assign(dg2 = lambda x: (x.rndf2 * 0.07) + (x.neural2 * 0.33) + (x.xgb2 * 0.53) + (x.logReg2 * 0.07))\r\n",
    "trainData = trainData.assign(dg3 = lambda x: (x.rndf3 * 0.07) + (x.neural3 * 0.33) + (x.xgb3 * 0.53) + (x.logReg3 * 0.07))\r\n",
    "trainData = trainData[['dg1', 'dg2', 'dg3']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "dgTest = []\r\n",
    "for x in range(0, 86867):\r\n",
    "    dgTest.append(1 if ((trainData.dg1[x] > trainData.dg2[x]) and (trainData.dg1[x] > trainData.dg2[x])) else 2 if ((trainData.dg2[x] > trainData.dg3[x]) and (trainData.dg2[x] > trainData.dg1[x])) else 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "f1_score(validation_labels, dgTest, average='micro')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7505151553524353"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dgFinal = []\r\n",
    "for x in range(0, 86868):\r\n",
    "    dgFinal.append(1 if ((testData.dg1[x] > testData.dg2[x]) and (testData.dg1[x] > testData.dg2[x])) else 2 if ((testData.dg2[x] > testData.dg3[x]) and (testData.dg2[x] > testData.dg1[x])) else 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\r\n",
    "my_submission = pd.DataFrame(data=dgFinal,\r\n",
    "                             columns=submission_format.columns,\r\n",
    "                             index=submission_format.index)\r\n",
    "my_submission.to_csv('submissionEnsamble.csv')\r\n",
    "my_submission"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.74561110663428 primer intento ensamble con solver = 'lbfgs'"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "88ce181b8cd0eb812200b9b411a136cd9c7c972aa91497a27a228178326dd49d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}