{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "88ce181b8cd0eb812200b9b411a136cd9c7c972aa91497a27a228178326dd49d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for combining the preprocess with model training\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# for optimizing the hyperparameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels_original = pd.read_csv('train_labels.csv',low_memory=False,index_col='building_id')\n",
    "df_train_values_original = pd.read_csv('train_values.csv',low_memory=False, index_col='building_id', dtype= {\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})\n",
    "df_test_values_original = pd.read_csv('test_values.csv',low_memory=False, index_col='building_id', dtype= {\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_subset = pd.get_dummies(df_train_values_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo1 = pd.get_dummies(train_values_subset[\"geo_level_1_id\"])\n",
    "geo1Names = {}\n",
    "for x in geo1.columns: geo1Names[x] = ('geo1_'+ str(x))\n",
    "geo1 = geo1.rename(geo1Names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo2 = pd.get_dummies(train_values_subset[\"geo_level_2_id\"])\n",
    "geo2Names = {}\n",
    "for x in geo2.columns: geo2Names[x] = ('geo2_'+ str(x))\n",
    "geo2 = geo2.rename(geo2Names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1510"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_values_subset = train_values_subset.drop([\"geo_level_2_id\", \"geo_level_3_id\", \"geo_level_1_id\"], axis=1)\n",
    "train_values_subset = pd.concat([train_values_subset, geo1, geo2], axis=1)\n",
    "# train_values_subset.head()\n",
    "train_values_subset.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_subset = pd.get_dummies(df_test_values_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo1Test = pd.get_dummies(test_values_subset[\"geo_level_1_id\"])\n",
    "geo1TestNames = {}\n",
    "for x in geo1Test.columns: geo1TestNames[x] = ('geo1_'+ str(x))\n",
    "geo1Test = geo1Test.rename(geo1TestNames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo2Test = pd.get_dummies(test_values_subset[\"geo_level_2_id\"])\n",
    "geo2TestNames = {}\n",
    "for x in geo2Test.columns: geo2TestNames[x] = ('geo2_'+ str(x))\n",
    "geo2Test = geo2Test.rename(geo2TestNames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "test_values_subset = test_values_subset.drop([\"geo_level_2_id\", \"geo_level_3_id\", \"geo_level_1_id\"], axis=1)\n",
    "test_values_subset = pd.concat([test_values_subset, geo1Test, geo2Test], axis=1)\n",
    "# test_values_subset.head()\n",
    "test_values_subset.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in geo2Test.columns.difference(geo2.columns): train_values_subset[x] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in geo2.columns.difference(geo2Test.columns): test_values_subset[x] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1514"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "test_values_subset.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1514"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_values_subset.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_subset = df_train_labels_original['damage_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, validation_values = (train_values_subset.iloc[0:173733], train_values_subset.iloc[173733:-1])\n",
    "train_labels, validation_labels = (train_labels_subset.iloc[0:173733], train_labels_subset.iloc[173733:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndfor = RandomForestClassifier(n_estimators=100, max_features=None, bootstrap=True, n_jobs=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=None, n_estimators=1000, n_jobs=-1)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "rndfor.fit(train_values_subset, train_labels_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rndfor.predict(train_values_subset) \n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "rndfor.score(train_values_subset, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3, 2, 3, ..., 3, 2, 3], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9683232220904755"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# f1_score(train_values_subset, predictions, average='micro')\n",
    "f1_score(train_labels_subset, predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.235628412784295"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6073983255995316"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "np.std(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rndfor.predict(test_values_subset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=predictions,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "my_submission.to_csv('submission5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}