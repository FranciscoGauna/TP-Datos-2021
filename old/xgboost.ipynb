{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 166.7 MB 3.7 kB/s  eta 0:00:01  |█▏                              | 5.9 MB 3.7 MB/s eta 0:00:44     |█▊                              | 9.0 MB 3.7 MB/s eta 0:00:44     |█▉                              | 9.6 MB 3.7 MB/s eta 0:00:43     |██                              | 11.0 MB 3.7 MB/s eta 0:00:43     |██▉                             | 14.8 MB 3.7 MB/s eta 0:00:42     |████▏                           | 21.8 MB 25.1 MB/s eta 0:00:06     |████▎                           | 22.5 MB 25.1 MB/s eta 0:00:06     |█████                           | 26.1 MB 25.1 MB/s eta 0:00:06     |█████▎                          | 27.2 MB 25.1 MB/s eta 0:00:06     |█████▍                          | 28.2 MB 25.1 MB/s eta 0:00:06     |█████▍                          | 28.2 MB 25.1 MB/s eta 0:00:06     |█████▌                          | 28.6 MB 25.1 MB/s eta 0:00:06     |█████▌                          | 28.7 MB 25.1 MB/s eta 0:00:06     |█████▌                          | 28.8 MB 1.5 MB/s eta 0:01:34     |█████▋                          | 29.2 MB 1.5 MB/s eta 0:01:34     |██████                          | 31.6 MB 1.5 MB/s eta 0:01:32     |██████▋                         | 34.7 MB 1.5 MB/s eta 0:01:30     |██████▉                         | 35.5 MB 1.5 MB/s eta 0:01:30     |███████                         | 37.0 MB 1.5 MB/s eta 0:01:29     |████████                        | 41.6 MB 4.4 MB/s eta 0:00:29     |████████▉                       | 46.0 MB 4.4 MB/s eta 0:00:28     |███████████▎                    | 58.9 MB 21.5 MB/s eta 0:00:06     |███████████▋                    | 60.3 MB 21.5 MB/s eta 0:00:05     |████████████                    | 62.8 MB 21.5 MB/s eta 0:00:05     |████████████▊                   | 66.4 MB 4.7 MB/s eta 0:00:22     |████████████▉                   | 66.9 MB 4.7 MB/s eta 0:00:22     |█████████████                   | 68.0 MB 4.7 MB/s eta 0:00:21     |█████████████▋                  | 71.2 MB 4.7 MB/s eta 0:00:21     |██████████████                  | 73.0 MB 4.7 MB/s eta 0:00:20     |██████████████▍                 | 74.8 MB 4.7 MB/s eta 0:00:20     |███████████████                 | 77.6 MB 16.8 MB/s eta 0:00:06     |███████████████                 | 78.6 MB 16.8 MB/s eta 0:00:06     |███████████████▌                | 80.8 MB 16.8 MB/s eta 0:00:06     |████████████████                | 83.9 MB 16.8 MB/s eta 0:00:05     |████████████████▌               | 86.0 MB 16.8 MB/s eta 0:00:05     |████████████████▋               | 86.4 MB 2.6 MB/s eta 0:00:31     |████████████████▊               | 87.2 MB 2.6 MB/s eta 0:00:31     |█████████████████▌              | 91.0 MB 2.6 MB/s eta 0:00:30     |█████████████████▊              | 92.4 MB 2.6 MB/s eta 0:00:29     |██████████████████▌             | 96.3 MB 29.1 MB/s eta 0:00:03     |██████████████████▋             | 97.1 MB 29.1 MB/s eta 0:00:03     |██████████████████▊             | 97.6 MB 29.1 MB/s eta 0:00:03     |██████████████████▉             | 98.2 MB 29.1 MB/s eta 0:00:03     |███████████████████             | 98.8 MB 29.1 MB/s eta 0:00:03     |███████████████████▊            | 102.5 MB 29.1 MB/s eta 0:00:03     |████████████████████            | 104.2 MB 29.1 MB/s eta 0:00:03     |████████████████████▎           | 105.6 MB 29.1 MB/s eta 0:00:03     |████████████████████▊           | 107.9 MB 19.5 MB/s eta 0:00:04     |█████████████████████           | 109.6 MB 19.5 MB/s eta 0:00:03     |█████████████████████▎          | 110.8 MB 19.5 MB/s eta 0:00:03     |█████████████████████▊          | 113.4 MB 19.5 MB/s eta 0:00:03     |██████████████████████          | 114.9 MB 19.5 MB/s eta 0:00:03     |██████████████████████▎         | 115.9 MB 19.5 MB/s eta 0:00:03     |███████████████████████▎        | 121.0 MB 4.5 MB/s eta 0:00:11     |███████████████████████▋        | 122.8 MB 4.5 MB/s eta 0:00:10     |███████████████████████▉        | 124.1 MB 4.5 MB/s eta 0:00:10     |████████████████████████        | 125.2 MB 4.5 MB/s eta 0:00:10     |████████████████████████▏       | 125.8 MB 4.5 MB/s eta 0:00:10     |████████████████████████▌       | 127.7 MB 4.5 MB/s eta 0:00:09     |████████████████████████▉       | 129.7 MB 4.5 MB/s eta 0:00:09     |██████████████████████████      | 134.9 MB 6.9 MB/s eta 0:00:05     |██████████████████████████▏     | 136.3 MB 6.9 MB/s eta 0:00:05     |██████████████████████████▉     | 139.9 MB 6.9 MB/s eta 0:00:04     |███████████████████████████     | 140.3 MB 6.9 MB/s eta 0:00:04     |███████████████████████████     | 140.8 MB 6.9 MB/s eta 0:00:04     |███████████████████████████▏    | 141.4 MB 6.9 MB/s eta 0:00:04     |███████████████████████████▍    | 142.5 MB 4.3 MB/s eta 0:00:06     |███████████████████████████▋    | 144.1 MB 4.3 MB/s eta 0:00:06     |████████████████████████████    | 145.5 MB 4.3 MB/s eta 0:00:05     |████████████████████████████▍   | 147.9 MB 4.3 MB/s eta 0:00:05     |████████████████████████████▊   | 149.6 MB 4.3 MB/s eta 0:00:04     |██████████████████████████████▊ | 160.0 MB 69.4 MB/s eta 0:00:01     |███████████████████████████████ | 162.1 MB 69.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from xgboost) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from xgboost) (1.18.5)\n",
      "Installing collected packages: xgboost\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/daiecasquero/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "Requirement already satisfied: pandas in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (1.0.5)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from xgboost) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/daiecasquero/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Installing collected packages: xgboost, sklearn\n",
      "Successfully installed sklearn-0.0 xgboost-1.4.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/daiecasquero/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle, islice\n",
    "import datetime as datetime\n",
    "import glob\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# for combining the preprocess with model training\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# for optimizing the hyperparameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('train_labels.csv',low_memory=False, dtype= {\n",
    "    'damage_grade':'uint8'\n",
    "}).set_index('building_id')\n",
    "train_values = pd.read_csv('train_values.csv',low_memory=False, dtype= {\n",
    "    'geo_level_1_id':'category', \n",
    "    'geo_level_2_id':'category',\n",
    "    'geo_level_3_id':'category', \n",
    "    'count_floors_pre_eq':'uint8',\n",
    "    'age':'uint16',\n",
    "    'area_percentage':'uint16', \n",
    "    'height_percentage':'uint16', \n",
    "    'land_surface_condition':'category', \n",
    "    'foundation_type':'category',\n",
    "    'roof_type':'category',\n",
    "    'ground_floor_type':'category',\n",
    "    'other_floor_type':'category',\n",
    "    'position':'category',\n",
    "    'plan_configuration':'category', \n",
    "    'has_superstructure_adobe_mud':'uint8',\n",
    "    'has_superstructure_mud_mortar_stone':'uint8',\n",
    "    'has_superstructure_stone_flag':'uint8',\n",
    "    'has_superstructure_cement_mortar_stone':'uint8', \n",
    "    'has_superstructure_mud_mortar_brick':'uint8', \n",
    "    'has_superstructure_cement_mortar_brick':'uint8', \n",
    "    'has_superstructure_timber':'uint8', \n",
    "    'has_superstructure_bamboo':'uint8',\n",
    "    'has_superstructure_rc_non_engineered':'uint8',\n",
    "    'has_superstructure_rc_engineered':'uint8',\n",
    "    'has_superstructure_other':'uint8', \n",
    "    'legal_ownership_status':'category',\n",
    "    'count_families':'uint16', \n",
    "    'has_secondary_use':'uint8', \n",
    "    'has_secondary_use_agriculture':'uint8', \n",
    "    'has_secondary_use_hotel':'uint8',\n",
    "    'has_secondary_use_rental':'uint8',\n",
    "    'has_secondary_use_institution':'uint8',\n",
    "    'has_secondary_use_school':'uint8', \n",
    "    'has_secondary_use_industry':'uint8', \n",
    "    'has_secondary_use_health_post':'uint8', \n",
    "    'has_secondary_use_gov_office':'uint8', \n",
    "    'has_secondary_use_use_police':'uint8', \n",
    "    'has_secondary_use_other':'uint8',\n",
    "}).set_index('building_id')\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802906</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94947</th>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590882</th>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201944</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688636</th>\n",
       "      <td>25</td>\n",
       "      <td>1335</td>\n",
       "      <td>1621</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669485</th>\n",
       "      <td>17</td>\n",
       "      <td>715</td>\n",
       "      <td>2060</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602512</th>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "      <td>8163</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151409</th>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>1851</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747594</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>9101</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260601 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            geo_level_1_id geo_level_2_id geo_level_3_id  count_floors_pre_eq  \\\n",
       "building_id                                                                     \n",
       "802906                   6            487          12198                    2   \n",
       "28830                    8            900           2812                    2   \n",
       "94947                   21            363           8973                    2   \n",
       "590882                  22            418          10694                    2   \n",
       "201944                  11            131           1488                    3   \n",
       "...                    ...            ...            ...                  ...   \n",
       "688636                  25           1335           1621                    1   \n",
       "669485                  17            715           2060                    2   \n",
       "602512                  17             51           8163                    3   \n",
       "151409                  26             39           1851                    2   \n",
       "747594                  21              9           9101                    3   \n",
       "\n",
       "             age  area_percentage  height_percentage land_surface_condition  \\\n",
       "building_id                                                                   \n",
       "802906        30                6                  5                      t   \n",
       "28830         10                8                  7                      o   \n",
       "94947         10                5                  5                      t   \n",
       "590882        10                6                  5                      t   \n",
       "201944        30                8                  9                      t   \n",
       "...          ...              ...                ...                    ...   \n",
       "688636        55                6                  3                      n   \n",
       "669485         0                6                  5                      t   \n",
       "602512        55                6                  7                      t   \n",
       "151409        10               14                  6                      t   \n",
       "747594        10                7                  6                      n   \n",
       "\n",
       "            foundation_type roof_type  ... has_secondary_use_hotel  \\\n",
       "building_id                            ...                           \n",
       "802906                    r         n  ...                       0   \n",
       "28830                     r         n  ...                       0   \n",
       "94947                     r         n  ...                       0   \n",
       "590882                    r         n  ...                       0   \n",
       "201944                    r         n  ...                       0   \n",
       "...                     ...       ...  ...                     ...   \n",
       "688636                    r         n  ...                       0   \n",
       "669485                    r         n  ...                       0   \n",
       "602512                    r         q  ...                       0   \n",
       "151409                    r         x  ...                       0   \n",
       "747594                    r         n  ...                       0   \n",
       "\n",
       "            has_secondary_use_rental has_secondary_use_institution  \\\n",
       "building_id                                                          \n",
       "802906                             0                             0   \n",
       "28830                              0                             0   \n",
       "94947                              0                             0   \n",
       "590882                             0                             0   \n",
       "201944                             0                             0   \n",
       "...                              ...                           ...   \n",
       "688636                             0                             0   \n",
       "669485                             0                             0   \n",
       "602512                             0                             0   \n",
       "151409                             0                             0   \n",
       "747594                             0                             0   \n",
       "\n",
       "            has_secondary_use_school  has_secondary_use_industry  \\\n",
       "building_id                                                        \n",
       "802906                             0                           0   \n",
       "28830                              0                           0   \n",
       "94947                              0                           0   \n",
       "590882                             0                           0   \n",
       "201944                             0                           0   \n",
       "...                              ...                         ...   \n",
       "688636                             0                           0   \n",
       "669485                             0                           0   \n",
       "602512                             0                           0   \n",
       "151409                             0                           0   \n",
       "747594                             0                           0   \n",
       "\n",
       "             has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "building_id                                                                \n",
       "802906                                   0                             0   \n",
       "28830                                    0                             0   \n",
       "94947                                    0                             0   \n",
       "590882                                   0                             0   \n",
       "201944                                   0                             0   \n",
       "...                                    ...                           ...   \n",
       "688636                                   0                             0   \n",
       "669485                                   0                             0   \n",
       "602512                                   0                             0   \n",
       "151409                                   0                             0   \n",
       "747594                                   0                             0   \n",
       "\n",
       "             has_secondary_use_use_police  has_secondary_use_other  \\\n",
       "building_id                                                          \n",
       "802906                                  0                        0   \n",
       "28830                                   0                        0   \n",
       "94947                                   0                        0   \n",
       "590882                                  0                        0   \n",
       "201944                                  0                        0   \n",
       "...                                   ...                      ...   \n",
       "688636                                  0                        0   \n",
       "669485                                  0                        0   \n",
       "602512                                  0                        0   \n",
       "151409                                  0                        0   \n",
       "747594                                  0                        0   \n",
       "\n",
       "             damage_grade  \n",
       "building_id                \n",
       "802906                  3  \n",
       "28830                   2  \n",
       "94947                   3  \n",
       "590882                  2  \n",
       "201944                  3  \n",
       "...                   ...  \n",
       "688636                  2  \n",
       "669485                  3  \n",
       "602512                  3  \n",
       "151409                  2  \n",
       "747594                  3  \n",
       "\n",
       "[260601 rows x 39 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_values.merge(train_labels, on='building_id')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('geo_level_1_id', axis=1)\n",
    "train = train.drop('geo_level_2_id', axis=1)\n",
    "train = train.drop('geo_level_3_id', axis=1)\n",
    "train = train.drop('land_surface_condition', axis=1)\n",
    "#train = train.drop('count_floors_pre_eq', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('roof_type', axis=1)\n",
    "train = train.drop('other_floor_type', axis=1)\n",
    "train = train.drop('position', axis=1)\n",
    "#train = train.drop('other_floor_type', axis=1)\n",
    "train = train.drop('plan_configuration', axis=1)\n",
    "train = train.drop('legal_ownership_status', axis=1)\n",
    "train = train.drop('ground_floor_type', axis=1)\n",
    "train = train.drop('foundation_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_value = train['damage_grade']\n",
    "train_data = train.iloc[:, train.columns != 'damage_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train_data, train_value, train_size=0.7, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = xgb.XGBClassifier(objective='reg:logistic', n_estimators=10, seed=123, learning_rate=0.7, \n",
    "                           max_depth=4, alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=30, base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.7, max_delta_step=None, max_depth=4,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='reg:logistic', random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, seed=123, subsample=None,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:27:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(alpha=30, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.7, max_delta_step=0, max_depth=4,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=10, n_jobs=4, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=123, reg_alpha=30,\n",
      "              reg_lambda=1, scale_pos_weight=None, seed=123, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Precisión xgboost train/test  0.590/0.594\n"
     ]
    }
   ],
   "source": [
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Realizo las predicciones\n",
    "y_pred = modelo.predict(X_train)\n",
    "predicciones = [round(value) for value in y_pred]\n",
    "# Evalúo las predicciones\n",
    "precision_train = accuracy_score(y_train, predicciones)\n",
    "\n",
    "# Repito el proceso con datos de evaluacion\n",
    "y_pred = modelo.predict(X_validation)\n",
    "predicciones = [round(value) for value in y_pred]\n",
    "\n",
    "# Evalúo las predicciones\n",
    "precision_test = accuracy_score(y_validation, predicciones)\n",
    "print(modelo)\n",
    "print('Precisión xgboost train/test  {0:.3f}/{1:.3f}'\n",
    "      .format(precision_train, precision_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'max_depth': [3, 4, 5, 8, 10],\n",
    "        'n_estimators': [5, 10, 20, 50],\n",
    "        'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        'alpha': [0, 5, 15, 30]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "param_comb = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(modelo, param_distributions=params, \n",
    "        n_iter=param_comb, n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x0000020EC72A1740>,\n",
       "                   estimator=XGBClassifier(alpha=30, base_score=None,\n",
       "                                           booster=None, colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.7,\n",
       "                                           max_delta_step=None, max_depth=4,\n",
       "                                           min_child_weight=Non...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None, seed=123,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=500, n_jobs=4,\n",
       "                   param_distributions={'alpha': [0, 5, 15, 30],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'learning_rate': [0.1, 0.3, 0.5, 0.7,\n",
       "                                                          0.9],\n",
       "                                        'max_depth': [3, 4, 5, 8, 10],\n",
       "                                        'n_estimators': [5, 10, 20, 50]},\n",
       "                   random_state=1001, verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 67.9min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 96.9min\n",
      "[Parallel(n_jobs=4)]: Done 1500 out of 1500 | elapsed: 127.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x0000020EC72A1740>,\n",
       "                   estimator=XGBClassifier(alpha=30, base_score=None,\n",
       "                                           booster=None, colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.7,\n",
       "                                           max_delta_step=None, max_depth=4,\n",
       "                                           min_child_weight=Non...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None, seed=123,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=500, n_jobs=4,\n",
       "                   param_distributions={'alpha': [0, 5, 15, 30],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'learning_rate': [0.1, 0.3, 0.5, 0.7,\n",
       "                                                          0.9],\n",
       "                                        'max_depth': [3, 4, 5, 8, 10],\n",
       "                                        'n_estimators': [5, 10, 20, 50]},\n",
       "                   random_state=1001, verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = random_search.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04307372, 0.59681815, 0.3601081 ],\n",
       "       [0.43316516, 0.5439617 , 0.02287317],\n",
       "       [0.04620108, 0.56988406, 0.38391486],\n",
       "       ...,\n",
       "       [0.07585122, 0.58564115, 0.33850768],\n",
       "       [0.02114557, 0.58264846, 0.39620596],\n",
       "       [0.0545476 , 0.54568654, 0.3997659 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(alpha=0, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=2, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.3, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=50, n_jobs=4, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, seed=123, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x0000020EC72A1740>,\n",
      "                   estimator=XGBClassifier(alpha=30, base_score=None,\n",
      "                                           booster=None, colsample_bylevel=None,\n",
      "                                           colsample_bynode=None,\n",
      "                                           colsample_bytree=None, gamma=None,\n",
      "                                           gpu_id=None, importance_type='gain',\n",
      "                                           interaction_constraints=None,\n",
      "                                           learning_rate=0.7,\n",
      "                                           max_delta_step=None, max_depth=4,\n",
      "                                           min_child_weight=Non...\n",
      "                                           random_state=None, reg_alpha=None,\n",
      "                                           reg_lambda=None,\n",
      "                                           scale_pos_weight=None, seed=123,\n",
      "                                           subsample=None, tree_method=None,\n",
      "                                           validate_parameters=None,\n",
      "                                           verbosity=None),\n",
      "                   n_iter=500, n_jobs=4,\n",
      "                   param_distributions={'alpha': [0, 5, 15, 30],\n",
      "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
      "                                        'learning_rate': [0.1, 0.3, 0.5, 0.7,\n",
      "                                                          0.9],\n",
      "                                        'max_depth': [3, 4, 5, 8, 10],\n",
      "                                        'n_estimators': [5, 10, 20, 50]},\n",
      "                   random_state=1001, verbose=3)\n",
      "Precisión xgboost train/test  0.614/0.601\n"
     ]
    }
   ],
   "source": [
    "# Realizo las predicciones\n",
    "y_pred = random_search.predict(X_train)\n",
    "predicciones = [round(value) for value in y_pred]\n",
    "# Evalúo las predicciones\n",
    "precision_train = accuracy_score(y_train, predicciones)\n",
    "\n",
    "# Repito el proceso con datos de evaluacion\n",
    "y_pred = random_search.predict(X_validation)\n",
    "predicciones = [round(value) for value in y_pred]\n",
    "\n",
    "# Evalúo las predicciones\n",
    "precision_test = accuracy_score(y_validation, predicciones)\n",
    "print(random_search)\n",
    "print('Precisión xgboost train/test  {0:.3f}/{1:.3f}'\n",
    "      .format(precision_train, precision_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 9.62469101, 10.49547577,  8.13808227,  8.11446516, 21.80566208,\n",
      "       10.61449067, 13.26746043,  8.03217371, 10.58706681, 16.67055289]), 'std_fit_time': array([0.04523287, 0.08111174, 0.01717539, 0.04314762, 0.11047848,\n",
      "       0.1382433 , 0.08456394, 0.00874173, 0.04972601, 1.27990643]), 'mean_score_time': array([0.17114194, 0.17057284, 0.14982057, 0.14905532, 0.26392182,\n",
      "       0.19270388, 0.19468212, 0.13495223, 0.16880989, 0.1649607 ]), 'std_score_time': array([0.01838932, 0.01797345, 0.00926216, 0.00248485, 0.00846168,\n",
      "       0.00623902, 0.00545539, 0.00821837, 0.00874689, 0.04133804]), 'param_max_depth': masked_array(data=[5, 4, 3, 3, 8, 4, 5, 3, 4, 8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[2, 1.5, 5, 1.5, 5, 2, 0.5, 0.5, 0.5, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 5, 'gamma': 2}, {'max_depth': 4, 'gamma': 1.5}, {'max_depth': 3, 'gamma': 5}, {'max_depth': 3, 'gamma': 1.5}, {'max_depth': 8, 'gamma': 5}, {'max_depth': 4, 'gamma': 2}, {'max_depth': 5, 'gamma': 0.5}, {'max_depth': 3, 'gamma': 0.5}, {'max_depth': 4, 'gamma': 0.5}, {'max_depth': 8, 'gamma': 2}], 'split0_test_score': array([0.58935649, 0.586939  , 0.58537668, 0.58503133, 0.59014587,\n",
      "       0.58679099, 0.58955383, 0.58601806, 0.58662654, 0.59080369]), 'split1_test_score': array([0.58894535, 0.58781061, 0.58341967, 0.58447218, 0.58920848,\n",
      "       0.58764616, 0.58910981, 0.58450507, 0.58736659, 0.5905899 ]), 'split2_test_score': array([0.5877545 , 0.58586324, 0.58456402, 0.5850245 , 0.58806697,\n",
      "       0.58673486, 0.58897148, 0.58499161, 0.5869651 , 0.59017202]), 'mean_test_score': array([0.58868545, 0.58687095, 0.58445346, 0.58484267, 0.58914044,\n",
      "       0.58705734, 0.58921171, 0.58517158, 0.58698608, 0.59052187]), 'std_test_score': array([0.00067934, 0.00079647, 0.00080276, 0.00026199, 0.00085007,\n",
      "       0.00041699, 0.00024842, 0.00063065, 0.00030249, 0.00026233]), 'rank_test_score': array([ 4,  7, 10,  9,  3,  5,  2,  8,  6,  1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78181"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_values.csv',low_memory=False, dtype= {\n",
    "    'geo_level_1_id':'category', \n",
    "    'geo_level_2_id':'category',\n",
    "    'geo_level_3_id':'category', \n",
    "    'count_floors_pre_eq':'uint8',\n",
    "    'age':'uint16',\n",
    "    'area_percentage':'uint16', \n",
    "    'height_percentage':'uint16', \n",
    "    'land_surface_condition':'category', \n",
    "    'foundation_type':'category',\n",
    "    'roof_type':'category',\n",
    "    'ground_floor_type':'category',\n",
    "    'other_floor_type':'category',\n",
    "    'position':'category',\n",
    "    'plan_configuration':'category', \n",
    "    'has_superstructure_adobe_mud':'uint8',\n",
    "    'has_superstructure_mud_mortar_stone':'uint8',\n",
    "    'has_superstructure_stone_flag':'uint8',\n",
    "    'has_superstructure_cement_mortar_stone':'uint8', \n",
    "    'has_superstructure_mud_mortar_brick':'uint8', \n",
    "    'has_superstructure_cement_mortar_brick':'uint8', \n",
    "    'has_superstructure_timber':'uint8', \n",
    "    'has_superstructure_bamboo':'uint8',\n",
    "    'has_superstructure_rc_non_engineered':'uint8',\n",
    "    'has_superstructure_rc_engineered':'uint8',\n",
    "    'has_superstructure_other':'uint8', \n",
    "    'legal_ownership_status':'category',\n",
    "    'count_families':'uint16', \n",
    "    'has_secondary_use':'uint8', \n",
    "    'has_secondary_use_agriculture':'uint8', \n",
    "    'has_secondary_use_hotel':'uint8',\n",
    "    'has_secondary_use_rental':'uint8',\n",
    "    'has_secondary_use_institution':'uint8',\n",
    "    'has_secondary_use_school':'uint8', \n",
    "    'has_secondary_use_industry':'uint8', \n",
    "    'has_secondary_use_health_post':'uint8', \n",
    "    'has_secondary_use_gov_office':'uint8', \n",
    "    'has_secondary_use_use_police':'uint8', \n",
    "    'has_secondary_use_other':'uint8',\n",
    "}).set_index('building_id')\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('geo_level_1_id', axis=1)\n",
    "test = test.drop('geo_level_2_id', axis=1)\n",
    "test = test.drop('geo_level_3_id', axis=1)\n",
    "test = test.drop('land_surface_condition', axis=1)\n",
    "#test = test.drop('count_floors_pre_eq', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('roof_type', axis=1)\n",
    "test = test.drop('other_floor_type', axis=1)\n",
    "test = test.drop('position', axis=1)\n",
    "#test = test.drop('other_floor_type', axis=1)\n",
    "test = test.drop('plan_configuration', axis=1)\n",
    "test = test.drop('legal_ownership_status', axis=1)\n",
    "test = test.drop('ground_floor_type', axis=1)\n",
    "test = test.drop('foundation_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = random_search.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01848812, 0.44088084, 0.54063106],\n",
       "       [0.02994292, 0.6846277 , 0.28542936],\n",
       "       [0.05369101, 0.54561335, 0.40069568],\n",
       "       ...,\n",
       "       [0.0606572 , 0.62307173, 0.31627104],\n",
       "       [0.04825808, 0.6449669 , 0.306775  ],\n",
       "       [0.34072724, 0.6231002 , 0.03617253]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for line in predic:\n",
    "    if line[0] > line [1] and line [0] > line [2]:\n",
    "        results.append(1)\n",
    "    elif line[1] > line[2]:\n",
    "        results.append(2)\n",
    "    else:\n",
    "        results.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "damages = pd.Series(results).rename(\"damage_grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        2\n",
       "2        2\n",
       "3        1\n",
       "4        2\n",
       "        ..\n",
       "86863    2\n",
       "86864    3\n",
       "86865    2\n",
       "86866    2\n",
       "86867    2\n",
       "Name: damage_grade, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test.reset_index()['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         300051\n",
       "1          99355\n",
       "2         890251\n",
       "3         745817\n",
       "4         421793\n",
       "          ...   \n",
       "86863     310028\n",
       "86864     663567\n",
       "86865    1049160\n",
       "86866     442785\n",
       "86867     501372\n",
       "Name: building_id, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.merge(ids, damages, left_index=True,right_index=True).set_index('building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300051</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99355</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890251</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421793</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310028</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663567</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049160</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442785</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501372</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86868 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             damage_grade\n",
       "building_id              \n",
       "300051                  3\n",
       "99355                   2\n",
       "890251                  2\n",
       "745817                  1\n",
       "421793                  2\n",
       "...                   ...\n",
       "310028                  2\n",
       "663567                  3\n",
       "1049160                 2\n",
       "442785                  2\n",
       "501372                  2\n",
       "\n",
       "[86868 rows x 1 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = xgb.XGBClassifier()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Realizo las predicciones\n",
    "y_pred = modelo.predict(test)\n",
    "predicciones = [round(value) for value in y_pred]\n",
    "# Evalúo las predicciones\n",
    "precision_train = accuracy_score(y_train, predicciones)\n",
    "print(modelo)\n",
    "print('Precisión xgboost train/test  {0:.3f}/{1:.3f}'\n",
    "      .format(precision_train, precision_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test.reset_index()['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         300051\n",
       "1          99355\n",
       "2         890251\n",
       "3         745817\n",
       "4         421793\n",
       "          ...   \n",
       "86863     310028\n",
       "86864     663567\n",
       "86865    1049160\n",
       "86866     442785\n",
       "86867     501372\n",
       "Name: building_id, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "damages = pd.Series(predicciones).rename(\"damage_grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        2\n",
       "2        2\n",
       "3        1\n",
       "4        3\n",
       "        ..\n",
       "86863    2\n",
       "86864    3\n",
       "86865    2\n",
       "86866    2\n",
       "86867    2\n",
       "Name: damage_grade, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit_xgboost_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
