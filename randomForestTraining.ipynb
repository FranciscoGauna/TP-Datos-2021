{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "88ce181b8cd0eb812200b9b411a136cd9c7c972aa91497a27a228178326dd49d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "import pandas as pd\r\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# for preprocessing the data\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "# the model\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "# for optimizing the hyperparameters of the pipeline\r\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "df_train_labels_original = pd.read_csv('train_labels.csv',low_memory=False,index_col='building_id')\r\n",
    "df_train_values_original = pd.read_csv('train_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})\r\n",
    "df_test_values_original = pd.read_csv('test_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "train_values_subset = pd.get_dummies(df_train_values_original)\r\n",
    "train_labels_subset = df_train_labels_original['damage_grade']\r\n",
    "\r\n",
    "validation_size = df_train_values_original.index.size - df_test_values_original.index.size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "test_values_subset = pd.get_dummies(df_test_values_original)\r\n",
    "geo1Test = pd.get_dummies(test_values_subset[\"geo_level_1_id\"])\r\n",
    "geo1TestNames = {}\r\n",
    "for x in geo1Test.columns: geo1TestNames[x] = ('geo1Test_'+ str(x))\r\n",
    "geo1Test = geo1Test.rename(geo1TestNames, axis=1)\r\n",
    "test_values_subset = pd.concat([test_values_subset, geo1Test], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "geo1 = pd.get_dummies(train_values_subset[\"geo_level_1_id\"])\r\n",
    "geo1Names = {}\r\n",
    "for x in geo1.columns: geo1Names[x] = ('geo1_'+ str(x))\r\n",
    "geo1 = geo1.rename(geo1Names, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "geo2 = pd.get_dummies(train_values_subset[\"geo_level_2_id\"])\r\n",
    "geo2Names = {}\r\n",
    "for x in geo2.columns: geo2Names[x] = ('geo2_'+ str(x))\r\n",
    "geo2 = geo2.rename(geo2Names, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "train_values_subset = pd.concat([train_values_subset, geo1], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "train_values, validation_values = (train_values_subset.iloc[0:173733], train_values_subset.iloc[173733:-1])\r\n",
    "train_labels, validation_labels = (train_labels_subset.iloc[0:173733], train_labels_subset.iloc[173733:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "param_grid = {\r\n",
    "        'n_estimators': [100, 150, 200, 300, 400],\r\n",
    "        'min_samples_split': [0.01, 0.1, 0.25, 0.5, 0.75, 0.99],\r\n",
    "        'min_samples_leaf': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5],\r\n",
    "        'max_features': ['auto', 'log2', None],\r\n",
    "        'n_jobs': [6],\r\n",
    "        'bootstrap':[True]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "rs_clf = RandomizedSearchCV(RandomForestClassifier(), param_grid, verbose=2, scoring='f1_micro', cv=2, n_iter=50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rs_clf.fit(train_values, train_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rs_clf.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "rndfor = RandomForestClassifier(n_estimators=200, min_samples_split = 0.01, min_samples_leaf = 0.01, max_features=None, bootstrap=True, n_jobs=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "rndfor.fit(train_values, train_labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=None, min_samples_leaf=0.01,\n",
       "                       min_samples_split=0.01, n_estimators=200, n_jobs=2)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "predictions = rndfor.predict(validation_values) \r\n",
    "predictionsProba = rndfor.predict_proba(validation_values) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "df_prediction_rndForest = pd.DataFrame(predictionsProba, columns = ['rndf1', 'rndf2', 'rndf3'])\r\n",
    "df_prediction_rndForest.to_csv(\"randomForestPredictionProbaTrain.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "f1_score(validation_labels, predictions, average='micro')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6645676724187551"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\r\n",
    "my_submission = pd.DataFrame(data=predictions,\r\n",
    "                             columns=submission_format.columns,\r\n",
    "                             index=submission_format.index)\r\n",
    "my_submission.to_csv('submissionRandomForest.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}