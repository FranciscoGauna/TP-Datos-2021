{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "import pandas as pd\r\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "# for optimizing the hyperparameters of the pipeline\r\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "import xgboost as xgb\r\n",
    "from xgboost.sklearn import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "df_train_labels_original = pd.read_csv('train_labels.csv',low_memory=False,index_col='building_id')\r\n",
    "df_train_values_original = pd.read_csv('train_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})\r\n",
    "df_test_values_original = pd.read_csv('test_values.csv',low_memory=False, index_col='building_id', dtype= {\r\n",
    "'geo_level_1_id':'uint8', 'geo_level_2_id':'uint16', 'geo_level_3_id':'uint16', 'count_floors_pre_eq':'uint8','age':'uint16', 'area_percentage':'uint16', 'height_percentage':'uint16', \r\n",
    "'land_surface_condition':'category', 'foundation_type':'category', 'roof_type':'category', 'ground_floor_type':'category', 'other_floor_type':'category', 'position':'category','plan_configuration':'category', \r\n",
    "'has_superstructure_adobe_mud':'bool', 'has_superstructure_mud_mortar_stone':'bool','has_superstructure_stone_flag':'bool', 'has_superstructure_cement_mortar_stone':'bool', 'has_superstructure_mud_mortar_brick':'bool', 'has_superstructure_cement_mortar_brick':'bool', 'has_superstructure_timber':'bool', 'has_superstructure_bamboo':'bool', 'has_superstructure_rc_non_engineered':'bool', 'has_superstructure_rc_engineered':'bool', 'has_superstructure_other':'bool', \r\n",
    "'legal_ownership_status':'category', 'count_families':'uint16', \r\n",
    "'has_secondary_use':'bool', 'has_secondary_use_agriculture':'bool', 'has_secondary_use_hotel':'bool', 'has_secondary_use_rental':'bool', 'has_secondary_use_institution':'bool', 'has_secondary_use_school':'bool', 'has_secondary_use_industry':'bool', 'has_secondary_use_health_post':'bool', 'has_secondary_use_gov_office':'bool', 'has_secondary_use_use_police':'bool', 'has_secondary_use_other':'bool',})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "train_values_subset = pd.get_dummies(df_train_values_original)\r\n",
    "train_labels_subset = df_train_labels_original['damage_grade']\r\n",
    "\r\n",
    "validation_size = df_train_values_original.index.size - df_test_values_original.index.size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "test_values_subset = pd.get_dummies(df_test_values_original)\r\n",
    "geo1Test = pd.get_dummies(test_values_subset[\"geo_level_1_id\"])\r\n",
    "geo1TestNames = {}\r\n",
    "for x in geo1Test.columns: geo1TestNames[x] = ('geo1Test_'+ str(x))\r\n",
    "geo1Test = geo1Test.rename(geo1TestNames, axis=1)\r\n",
    "\r\n",
    "geo2Test = pd.get_dummies(test_values_subset[\"geo_level_2_id\"])\r\n",
    "geo2TestNames = {}\r\n",
    "for x in geo2Test.columns: geo2TestNames[x] = ('geo2_'+ str(x))\r\n",
    "geo2Test = geo2Test.rename(geo2TestNames, axis=1)\r\n",
    "geo2Test = geo2Test[['geo2_36', 'geo2_39', 'geo2_51', 'geo2_88', 'geo2_105', 'geo2_142',\r\n",
    "       'geo2_158', 'geo2_173', 'geo2_229', 'geo2_233', 'geo2_258', 'geo2_303',\r\n",
    "       'geo2_323', 'geo2_363', 'geo2_399', 'geo2_421', 'geo2_477', 'geo2_508',\r\n",
    "       'geo2_533', 'geo2_566', 'geo2_582', 'geo2_617', 'geo2_641', 'geo2_673',\r\n",
    "       'geo2_682', 'geo2_715', 'geo2_797', 'geo2_811', 'geo2_817', 'geo2_819',\r\n",
    "       'geo2_839', 'geo2_856', 'geo2_864', 'geo2_886', 'geo2_896', 'geo2_937',\r\n",
    "       'geo2_977', 'geo2_1001', 'geo2_1009', 'geo2_1023', 'geo2_1050',\r\n",
    "       'geo2_1074', 'geo2_1080', 'geo2_1132', 'geo2_1149', 'geo2_1155',\r\n",
    "       'geo2_1183', 'geo2_1253', 'geo2_1313', 'geo2_1401']]\r\n",
    "\r\n",
    "test_values_subset = pd.concat([test_values_subset, geo1Test], axis=1)\r\n",
    "\r\n",
    "mean_df = pd.read_csv('geolevel_2_id_mean.csv',low_memory=False)\r\n",
    "test_values_subset = test_values_subset.reset_index().merge(mean_df,on='geo_level_2_id',how='left').set_index('building_id')\r\n",
    "average_damage = pd.get_dummies(df_train_labels_original['damage_grade'][:int(len(df_train_labels_original)/2)]).mean().values\r\n",
    "test_values_subset['0'] = test_values_subset['0'].fillna(average_damage[0])\r\n",
    "test_values_subset['1'] = test_values_subset['1'].fillna(average_damage[1])\r\n",
    "test_values_subset['2'] = test_values_subset['2'].fillna(average_damage[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "geo1 = pd.get_dummies(train_values_subset[\"geo_level_1_id\"])\r\n",
    "geo1Names = {}\r\n",
    "for x in geo1.columns: geo1Names[x] = ('geo1_'+ str(x))\r\n",
    "geo1 = geo1.rename(geo1Names, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "geo2 = pd.get_dummies(train_values_subset[\"geo_level_2_id\"])\r\n",
    "geo2Names = {}\r\n",
    "for x in geo2.columns: geo2Names[x] = ('geo2_'+ str(x))\r\n",
    "geo2 = geo2.rename(geo2Names, axis=1)\r\n",
    "geo2 = geo2[['geo2_36', 'geo2_39', 'geo2_51', 'geo2_88', 'geo2_105', 'geo2_142',\r\n",
    "       'geo2_158', 'geo2_173', 'geo2_229', 'geo2_233', 'geo2_258', 'geo2_303',\r\n",
    "       'geo2_323', 'geo2_363', 'geo2_399', 'geo2_421', 'geo2_477', 'geo2_508',\r\n",
    "       'geo2_533', 'geo2_566', 'geo2_582', 'geo2_617', 'geo2_641', 'geo2_673',\r\n",
    "       'geo2_682', 'geo2_715', 'geo2_797', 'geo2_811', 'geo2_817', 'geo2_819',\r\n",
    "       'geo2_839', 'geo2_856', 'geo2_864', 'geo2_886', 'geo2_896', 'geo2_937',\r\n",
    "       'geo2_977', 'geo2_1001', 'geo2_1009', 'geo2_1023', 'geo2_1050',\r\n",
    "       'geo2_1074', 'geo2_1080', 'geo2_1132', 'geo2_1149', 'geo2_1155',\r\n",
    "       'geo2_1183', 'geo2_1253', 'geo2_1313', 'geo2_1401']]\r\n",
    "# estos geo2_id fueron seleccionados con el xgboostFeatureSelection, elegimos los 50 mas importantes segun el resultado, agregarlos no tuvo mucho impacto pero mejoro un poco, \r\n",
    "# agregar todos tenia un impacto negativo, se podria buscar cuantos Ids de geo2 son optimo pero no creo que se justifique el trabajo, mejora menos de 0.005 en los test que hicimos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "train_values_subset = pd.concat([train_values_subset, geo1], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "mean_df = pd.read_csv('geolevel_2_id_mean.csv',low_memory=False)\r\n",
    "train_values_subset = train_values_subset.reset_index().merge(mean_df,on='geo_level_2_id',how='left').set_index('building_id')\r\n",
    "average_damage = pd.get_dummies(df_train_labels_original['damage_grade'][:int(len(df_train_labels_original)/2)]).mean().values\r\n",
    "train_values_subset['0'] = train_values_subset['0'].fillna(average_damage[0])\r\n",
    "train_values_subset['1'] = train_values_subset['1'].fillna(average_damage[1])\r\n",
    "train_values_subset['2'] = train_values_subset['2'].fillna(average_damage[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "train_values, validation_values = (train_values_subset.iloc[0:173733], train_values_subset.iloc[173733:-1])\r\n",
    "train_labels, validation_labels = (train_labels_subset.iloc[0:173733], train_labels_subset.iloc[173733:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "param_grid = {\r\n",
    "        'max_depth': [3, 5, 6, 7, 8, 10],\r\n",
    "        'learning_rate': [0.1, 0.4, 0.43, 0.45, 0.5, 0.7],\r\n",
    "        'subsample': [0.5, 0.75, 1.0],\r\n",
    "        'colsample_bytree': [0.1, 0.5, 0.7, 0.8, 0.9, 1.0],\r\n",
    "        'colsample_bylevel': [0.1, 0.5, 0.8, 1.0],\r\n",
    "        'colsample_bynode': [0.1, 0.3, 0.5, 0.75, 0.9, 1.0],\r\n",
    "        'min_child_weight': [0.1, 0.5, 1.0, 3.0, 5.0, 7.0, 10.0, 15, 20],\r\n",
    "        'gamma': [0, 0.1, 0.15, 0.25, 0.5, 1],\r\n",
    "        'reg_lambda': [0.1, 0.5, 1.0, 5.0, ],\r\n",
    "        'reg_alpha': [0.1, 1.0, 5.0, 10.0],\r\n",
    "        'n_estimators': [100, 200, 300, 400, 500]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "rs_clf = RandomizedSearchCV(XGBClassifier(), param_grid, verbose=2, scoring='f1_micro', cv=2, n_iter=150)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "# rs_clf.fit(train_values, train_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "# rs_clf.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "modelo = xgb.XGBClassifier(eta=0.4, n_estimators=400, subsample=1, \r\n",
    "                        reg_lambda=0.5, reg_alpha= 5, min_child_weight=3, max_depth=6, \r\n",
    "                        gamma=0.25, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "modelo.fit(train_values_subset, train_labels_subset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "predictions = modelo.predict(test_values_subset) \r\n",
    "# predictionsProba = modelo.predict_proba(validation_values) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "f1_score(validation_labels, predictions, average='micro')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7453002866451012"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una parte del proceso de desarrollo, no es exaustivo ni completo, solo algunas cosas que fueron siendo anotadas aca\r\n",
    "\r\n",
    "- 0.7237961481345045 normal features + geolevel 1 y 2 categorizado\r\n",
    "- 0.7129174485132443 selected features del anterior\r\n",
    "- 0.7275720354104551 new best, normal features. solo get dummys\r\n",
    "- 0.6717856032785753 normal features, selected. muy pocas categorias\r\n",
    "- 0.7248322147651006 normal features + geoLevel1 categorizado.\r\n",
    "- 0.6693450907709487 normal features + geolevel1 categorizado selected (solo 24 features)\r\n",
    "- 0.7398513436249285 score con todos los datos, con normal features + geolevel1 categorizado\r\n",
    "- Score real con lo de arriba: 0.7249\r\n",
    "- cambiar a dart no trae mejoras\r\n",
    "- cambiar a gblinear empeora\r\n",
    "\r\n",
    "- 0.7262596843450332 baseline \r\n",
    "- 0.738093867636732 eta 0.7\r\n",
    "- 0.7415474230720526 eta 0.7, n_estimators = 200\r\n",
    "- 0.7438152578079132 eta=0.43, n_estimators=300\r\n",
    "\r\n",
    "- usar randomized search y probar otros algoritmos\r\n",
    "- 0.744264220014505 params3\r\n",
    "- 0.7459334384749099 con 50 geolevels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\r\n",
    "my_submission = pd.DataFrame(data=predictions,\r\n",
    "                             columns=submission_format.columns,\r\n",
    "                             index=submission_format.index)\r\n",
    "my_submission.to_csv('submissionXgBoost_meanEncoding.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "source": [
    "df_prediction_xgBoost = pd.DataFrame(predictionsProba, columns = ['xgb1', 'xgb2', 'xgb3'])\r\n",
    "df_prediction_xgBoost.to_csv('xgBoostPredictionProbaTrain.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "88ce181b8cd0eb812200b9b411a136cd9c7c972aa91497a27a228178326dd49d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}